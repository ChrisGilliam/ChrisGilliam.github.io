<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Christopher  Gilliam | Publications</title>
    <meta name="author" content="Christopher  Gilliam" />
    <meta name="description" content="Publication list generated by jekyll-scholar." />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/wave-square-solid.svg"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://chrisgilliam.github.io/publications/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
  <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://ChrisGilliam.github.io/">
       <span class="font-weight-bold">Christopher</span>   Gilliam
      </a>
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">About
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/news/">News
            </a>
          </li>
          

          <!-- Other pages -->
          <li class="nav-item active">
            <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
          </li>
          <li class="nav-item ">
            <a class="nav-link" href="/research/">Research</a>
          </li>

          <!-- Toogle theme mode -->
          <div class="toggle-container">
            <a id="light-toggle">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </a>
          </div>
        </ul>
      </div>
    </div>
  </nav>
</header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
  <div class="post">

    <header class="post-header">
      <h1 class="post-title">Publications</h1>
      <p class="post-description">Publication list generated by jekyll-scholar.</p>
    </header>

    <article>
      <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">Preprint</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Li2022" class="col-sm-10">
    
      <div class="title">Gravity Aided Navigation using Viterbi Map Matching Algorithm</div>
      <div class="author">W. Li, 
                  <em>C. Gilliam</em>, X. Wang, A. Kealy, A. Greentree, and B. Moran
      </div>

      <div class="periodical">
      
        <em>arXiv</em>,
      
      
      
      
      
      
        Preprint
      
      </div>
    

    <div class="links">
    
    
      <a href="http://dx.doi.org/10.48550/arXiv.2204.10492" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
      <a href="http://arxiv.org/abs/arXiv:2204.10492" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Sun2023" class="col-sm-10">
    
      <div class="title">Mapping Extended Landmarks for Radar SLAM</div>
      <div class="author">S. Sun, 
                  <em>C. Gilliam</em>, <a href="http://rfant.org.au/" target="_blank" rel="noopener noreferrer">K. Ghorbani</a>, G. Matthews, and <a href="https://beteje.github.io/" target="_blank" rel="noopener noreferrer">B. Jelfs</a>
                  
      </div>

      <div class="periodical">
      
        <em>In </em>, ,
      
      
      
      
        pp. –,
      
      
      
        Preprint
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.48550/arXiv.2210.17207" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
      <a href="http://arxiv.org/abs/arXiv:2210.17207" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/ICASSP2023_arXiv.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Simultaneous localization and mapping (SLAM) using automotive radar sensors can provide enhanced sensing capabilities for autonomous systems. In SLAM applications, with a greater requirement for the environment map, information on the extent of landmarks is vital for precise navigation and path planning. Although object extent estimation has been successfully applied in target tracking, its adaption to SLAM remains unaddressed due to the additional uncertainty of the sensor platform, bias in the odometer reading, as well as the measurement non-linearity. In this paper, we propose to incorporate the Bayesian random matrix approach to estimate the extent of landmarks in radar SLAM. We describe the details for implementation of landmark extent initialization, prediction and update. To validate the performance of our proposed approach we compare with the model-free ellipse fitting algorithm with results showing more consistent extent estimation. We also demonstrate that exploiting the landmark extent in the state update can improve localization accuracy.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Wang2022" class="col-sm-10">
    
      <div class="title">Probabilistic Map Matching for Robust Inertial Navigation Aiding</div>
      <div class="author">X. Wang, 
                  <em>C. Gilliam</em>, A. Kealy, J. Close, and B. Moran
      </div>

      <div class="periodical">
      
        <em>NAVIGATION: Journal of the Institute of Navigation</em>,
      
      
      
      
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.48550/arXiv.2203.16932" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
      <a href="http://arxiv.org/abs/arXiv:2203.16932" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Robust aiding of inertial navigation systems in GNSS-denied environments is critical for the removal of accumulated navigation error caused by the drift and bias inherent in inertial sensors. One way to perform such an aiding uses matching of geophysical measurements, such as gravimetry, gravity gradiometry or magnetometry, with a known geo-referenced map. Although simple in concept, this map matching procedure is challenging: the measurements themselves are noisy; their associated spatial location is uncertain; and the measurements may match multiple points within the map (i.e. non-unique solution). In this paper, we propose a probabilistic multiple hypotheses tracker to solve the map matching problem and allow robust inertial navigation aiding. Our approach addresses the problem both locally, via probabilistic data association, and temporally by incorporating the underlying platform kinematic constraints into the tracker. The map matching output is then integrated into the navigation system using an unscented Kalman filter. Additionally, we present a statistical measure of local map information density – the map feature variability – and use it to weight the output covariance of the proposed algorithm. The effectiveness and robustness of the proposed algorithm are demonstrated using a navigation scenario involving gravitational map matching.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Wang2021a" class="col-sm-10">
    
      <div class="title">Improving measurement performance via fusion of classical and quantum accelerometers</div>
      <div class="author">X. Wang, A. Kealy, 
                  <em>C. Gilliam</em>, S. Haine, J. Close, B. Moran, K. Talbot, S. Williams, K. Hardman, C. Freier, P. Wigley, A. White, S. Szigeti, and S. Legge
      </div>

      <div class="periodical">
      
        <em>The Journal of Navigation</em>,
      
      
      
      
        pp. 1-12,
      
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1017/S0373463322000637" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
      <a href="http://arxiv.org/abs/arXiv:2103.09378" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/Nav2023_Xuezhi.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>While quantum accelerometers sense with extremely low drift and low bias, their practical sensing capabilities face at least two limitations compared with classical accelerometers: a lower sample rate due to cold atom interrogation time; and a reduced dynamic range due to signal phase wrapping. In this paper, we propose a maximum likelihood probabilistic data fusion method, under which the actual phase of the quantum accelerometer can be unwrapped by fusing it with the output of a classical accelerometer on the platform. Consequently, the recovered measurement from the quantum accelerometer is used to estimate bias and drift of the classical accelerometer which is then removed from the system output. We demonstrate the enhanced error performance achieved by the proposed fusion method using a simulated 1D accelerometer precision test scenario. We conclude with a discussion on fusion error and potential solutions.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Kustner2022" class="col-sm-10">
    
      <div class="title">Self-Supervised Motion-Corrected Image Reconstruction Network for 4D Magnetic Resonance Imaging of the Body Trunk</div>
      <div class="author">
<a href="http://www.midaslab.org/" target="_blank" rel="noopener noreferrer">T. Küstner</a>, J. Pan, 
                  <em>C. Gilliam</em>, H. Qi, G. Cruz, K. Hammernik, <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>, D. Rueckert, R Botnar, C. Prieto, and S. Gatidis
      </div>

      <div class="periodical">
      
        <em>APSIPA Transactions on Signal and Information Processing</em>,
      
      
        Vol. 11,
      
      
        No. 1,
      
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1561/116.00000039" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/APSIPA_Trans2022.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Respiratory motion can cause artifacts in magnetic resonance imaging of the body trunk if patients cannot hold their breath or triggered acquisitions are not practical. Retrospective correction strategies usually cope with motion by fast imaging sequences under free-movement conditions followed by motion binning based on motion traces. These acquisitions yield sub-Nyquist sampled and motion-resolved k-space data. Motion states are linked to each other by non-rigid deformation fields. Usually, motion registration is formulated in image space which can however be impaired by aliasing artifacts or by estimation from low-resolution images. Subsequently, any motion-corrected reconstruction can be biased by errors in the deformation fields. In this work, we propose a deep-learning based motion-corrected 4D (3D spatial + time) image reconstruction which combines a non-rigid registration network and a 4D reconstruction network. Non-rigid motion is estimated in k-space and incorporated into the reconstruction network. The proposed method is evaluated on in-vivo 4D motion-resolved magnetic resonance images of patients with suspected liver or lung metastases and healthy subjects. The proposed approach provides 4D motion-corrected images and deformation fields. It enables a ∼14× accelerated acquisition with a 25-fold faster reconstruction than comparable approaches under consistent preservation of image quality for changing patients and motion patterns.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Sun2022" class="col-sm-10">
    
      <div class="title">Landmark Management in the Application of Radar SLAM</div>
      <div class="author">S. Sun, <a href="https://beteje.github.io/" target="_blank" rel="noopener noreferrer">B. Jelfs</a>, <a href="http://rfant.org.au/" target="_blank" rel="noopener noreferrer">K. Ghorbani</a>, G. Matthews, and <em>C. Gilliam</em>
                
      </div>

      <div class="periodical">
      
        <em>In Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA 2022)</em>, ,
      
      
      
      
        pp. 903–910,
      
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.23919/APSIPAASC55919.2022.9980051" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
      <a href="http://arxiv.org/abs/arXiv:2209.07199" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/APSIPA2022_arXiv.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/shuai000/SLAM_LandmarkManagement" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
      
      <a href="/assets/pdf/APSIPA2022_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper focuses on efficient landmark management in radar based simultaneous localization and mapping (SLAM). Landmark management is necessary in order to maintain a consistent map of the estimated landmarks relative to the estimate of the platform’s pose. This task is particularly important when faced with multiple detections from the same landmark and/or dynamic environments where the location of a landmark can change. A further challenge with radar data is the presence of false detections. Accordingly, we propose a simple yet efficient rule based solution for radar SLAM landmark management. Assuming a low-dynamic environment, there are several steps in our solution: new landmarks need to be detected and included, false landmarks need to be identified and removed, and the consistency of the landmarks registered in the map needs to be maintained. To illustrate our solution, we run an extended Kalman filter SLAM algorithm in an environment containing both stationary and temporally stationary landmarks. Our simulation results demonstrate that the proposed solution is capable of reliably managing landmarks even when faced with false detections and multiple detections from the same landmark.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Ristic2021" class="col-sm-10">
    
      <div class="title">Performance assessment of a system for reasoning under uncertainty</div>
      <div class="author">B. Ristic, 
                  <em>C. Gilliam</em>, and M. Byrne
      </div>

      <div class="periodical">
      
        <em>Information Fusion</em>,
      
      
        Vol. 71,
      
      
      
        pp. 11-16,
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/https://doi.org/10.1016/j.inffus.2021.01.006" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>From the early developments of machines for reasoning and decision making in higher-level information fusion, there was a need for a systematic and reliable evaluation of their performance. Performance evaluation is important for comparison and assessment of alternative solutions to real-world problems. In this paper we focus on one aspect of performance assessment for reasoning under uncertainty: the accuracy of the resulting belief (prediction or estimate). We propose a framework for assessment based on the assumption that the system under investigation is uncertain only due to stochastic variability (randomness), which is partially known. In this context we formulate a distance measure between the “ground truth” and the output of an automated system for reasoning in the framework of one of the non-additive uncertainty formalisms (such as imprecise probability theory, belief function theory or possibility theory). The proposed assessment framework is demonstrated with a simple numerical example.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Kustner2021" class="col-sm-10">
    
      <div class="title">LAPNet: Non-Rigid Registration Derived in k-Space for Magnetic Resonance Imaging</div>
      <div class="author">
<a href="http://www.midaslab.org/" target="_blank" rel="noopener noreferrer">T. Küstner</a>, J. Pan, H. Qi, G. Cruz, 
                  <em>C. Gilliam</em>, <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>, B. Yang, S. Gatidis, R. Botnar, and C. Prieto
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Medical Imaging</em>,
      
      
        Vol. 40,
      
      
        No. 12,
      
      
        pp. 3686–3697,
      
      
        dec
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/TMI.2021.3096131" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
      <a href="http://arxiv.org/abs/arXiv:2107.09060" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Physiological motion, such as cardiac and respiratory motion, during Magnetic Resonance (MR) image acquisition can cause image artifacts. Motion correction techniques have been proposed to compensate for these types of motion during thoracic scans, relying on accurate motion estimation from undersampled motion-resolved reconstruction. A particular interest and challenge lie in the derivation of reliable non-rigid motion fields from the undersampled motion-resolved data. Motion estimation is usually formulated in image space via diffusion, parametric-spline, or optical flow methods. However, image-based registration can be impaired by remaining aliasing artifacts due to the undersampled motion-resolved reconstruction. In this work, we describe a formalism to perform non-rigid registration directly in the sampled Fourier space, i.e. k-space. We propose a deep-learning based approach to perform fast and accurate non-rigid registration from the undersampled k-space data. The basic working principle originates from the Local All-Pass (LAP) technique, a recently introduced optical flow-based registration. The proposed LAPNet is compared against traditional and deep learning image-based registrations and tested on fully-sampled and highly-accelerated (with two undersampling strategies) 3D respiratory motion-resolved MR images in a cohort of 40 patients with suspected liver or lung metastases and 25 healthy subjects. The proposed LAPNet provided consistent and superior performance to image-based approaches throughout different sampling trajectories and acceleration factors.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Wang2021" class="col-sm-10">
    
      <div class="title">Toward Autonomous UAV Localization via Aerial Image Registration</div>
      <div class="author">X. Wang, A. Kealy, W. Li, <a href="https://beteje.github.io/" target="_blank" rel="noopener noreferrer">B. Jelfs</a>, 
                  <em>C. Gilliam</em>, S. Le May, and B. Moran
      </div>

      <div class="periodical">
      
        <em>Electronics</em>,
      
      
        Vol. 10,
      
      
        No. 4,
      
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.3390/electronics10040435" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Absolute localization of a flying UAV on its own in a global-navigation-satellite-system (GNSS)-denied environment is always a challenge. In this paper, we present a landmark-based approach where a UAV is automatically locked into the landmark scene shown in a georeferenced image via a feedback control loop, which is driven by the output of an aerial image registration. To pursue a real-time application, we design and implement a speeded-up-robust-features (SURF)-based image registration algorithm that focuses efficiency and robustness under a 2D geometric transformation. A linear UAV controller with signals of four degrees of freedom is derived from the estimated transformation matrix. The approach is validated in a virtual simulation environment, with experimental results demonstrating the effectiveness and robustness of the proposed UAV self-localization system.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Jelfs2021" class="col-sm-10">
    
      <div class="title">An Adaptive All-Pass Filter for Time-Varying Delay Estimation</div>
      <div class="author">
<a href="https://beteje.github.io/" target="_blank" rel="noopener noreferrer">B. Jelfs</a>, S. Sun, <a href="http://rfant.org.au/" target="_blank" rel="noopener noreferrer">K. Ghorbani</a>, and <em>C. Gilliam</em>
                
      </div>

      <div class="periodical">
      
        <em>IEEE Signal Processing Letters</em>,
      
      
        Vol. 28,
      
      
      
        pp. 628–632,
      
      
        
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/LSP.2021.3065889" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/Adaptive_All_Pass_arXiv.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/beteje/LAP_DelayEstimation/tree/master/Adaptive_AllPass" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
      <a href="https://drive.google.com/file/d/1UOHej75apX2VYoFO3EePnPZn7ykQYTK-/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
    
    
      
      <a href="/assets/pdf/ICASSP2022_Poster_LAP.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="/assets/pdf/ICASSP2022_Presentation_LAP.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The focus of this letter is the estimation of a delay between two signals. Such a problem is common in signal processing and particularly challenging when the delay is non-stationary in nature. Our proposed solution is based on an all-pass filter framework comprising of two elements: a time delay is equivalent to all-pass filtering and an all-pass filter can be represented in terms of a ratio of a finite impulse response (FIR) filter and its time reversal. Using these elements, we propose an adaptive filtering algorithm with an LMS style update that estimates the FIR filter coefficients and the time delay. Specifically, at each time step, the algorithm updates the filter coefficients based on a gradient descent update and then extracts an estimate of the time delay from the filter. We validate our algorithm on synthetic data demonstrating that it is both accurate and capable of tracking time-varying delays.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Angley2021" class="col-sm-10">
    
      <div class="title">Improving Automated Search for Underwater Threats Using Multistatic Sensor Fields by Incorporating Unconfirmed Track Information</div>
      <div class="author">D. Angley, S. Mehrkanoon, B. Moran, 
                  <em>C. Gilliam</em>, and S. Simakov
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Autonomous Systems (ICAS)</em>, ,
      
      
      
      
        pp. 1–5,
      
      
        aug
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICAS49788.2021.9551133" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICAS2021.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://drive.google.com/file/d/1_jBNSH9zael4UnAbE1EL0M1HC6Wbk4Cm/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
    
    
    
      
      <a href="/assets/pdf/ICAS2021_Slides.pptx" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Sonobuoy fields, comprising a network of sonar transmitters and receivers, are used to search for and track underwater targets. Although normally such fields are operated from a maritime patrol aircraft, automated scheduling and processing creates opportunities for employing them as autonomous sensor systems. The automated search mechanism considered in this work is controlled by modelling the presence of undetected threats in an Operational Area (OA) using a spatial probability density function (PDF), known as a threat map. The algorithm decides how to schedule waveform transmissions, known as pings, to efficiently search and clear the OA. A conventional approach is to update the threat map based on just the characteristics of the sonobuoy field and switch to a separate metric to track a target after track confirmation. In this study we address the phase when there are potential contacts which cannot yet be promoted to confirmed tracks. We develop a mechanism for probing the associated areas of interest while still remaining in the threat map driven search scheduling. To this end, we propose reinitialising the threat map after each transmission using an augmented PDF, where unconfirmed tracks are represented by weighted Gaussians. Simulations show that this approach significantly improves search performance, reducing the number of pings required to confirm a track, distance from a confirmed track to the target and the proportion of falsely confirmed tracks.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
      <span class="award badge"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">Best Paper Award<img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"></span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Ristic2020" class="col-sm-10">
    
      <div class="title">A tutorial on uncertainty modeling for machine reasoning</div>
      <div class="author">B. Ristic, 
                  <em>C. Gilliam</em>, M. Byrne, and A. Benavoli
      </div>

      <div class="periodical">
      
        <em>Information Fusion</em>,
      
      
        Vol. 55,
      
      
      
        pp. 30–44,
      
      
        mar
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1016/j.inffus.2019.08.001" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
      <a href="https://github.com/ChrisGilliam/Uncertainty_Modeling" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Increasingly we rely on machine intelligence for reasoning and decision making under uncertainty. This tutorial reviews the prevalent methods for model-based autonomous decision making based on observations and prior knowledge, primarily in the context of classification. Both observations and the knowledge-base available for reasoning are treated as being uncertain. Accordingly, the central themes of this tutorial are quantitative modeling of uncertainty, the rules required to combine such uncertain information, and the task of decision making under uncertainty. The paper covers the main approaches to uncertain knowledge representation and reasoning, in particular, Bayesian probability theory, possibility theory, reasoning based on belief functions and finally imprecise probability theory. The main feature of the tutorial is that it illustrates various approaches with several testing scenarios, and provides MATLAB solutions for them as a supplementary material for an interested reader.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Ristic2020a" class="col-sm-10">
    
      <div class="title">Decentralised multi-platform search for a hazardous source in a turbulent flow</div>
      <div class="author">B. Ristic, 
                  <em>C. Gilliam</em>, W. Moran, and J. L. Palmer
      </div>

      <div class="periodical">
      
        <em>Information Fusion</em>,
      
      
        Vol. 58,
      
      
      
        pp. 13–23,
      
      
        jun
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1016/j.inffus.2019.12.011" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/Decentralised_Search_IF2020.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The paper presents a cognitive strategy that enables an interconnected group of autonomous vehicles (moving robots) to search and localise a source of hazardous emissions (gas, biochemical particles) in a coordinated manner. Dispersion of the emitted substance is assumed to be affected by turbulence, resulting in the absence of concentration gradients. The key feature of the proposed search strategy is that it can be applied in a completely decentralised manner as long as the communication network of autonomous vehicles forms a connected graph. By decentralised operation we mean that each moving robot performs computations (i.e. source estimation and robot motion control) locally. Coordination is achieved by exchanging the data with the neighbours only, in a manner which does not require global knowledge of the communication network topology.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Yi2020" class="col-sm-10">
    
      <div class="title">Oscillation and self-propulsion of Leidenfrost droplets enclosed in cylindrical cavities</div>
      <div class="author">P. Yi, P. Thurgood, N. Nguyen, H. Abdelwahab, P. Petersen, 
                  <em>C. Gilliam</em>, <a href="http://rfant.org.au/" target="_blank" rel="noopener noreferrer">K. Ghorbani</a>, E. Pirogova, S. Y. Tang, and K. Khoshmanesh
      </div>

      <div class="periodical">
      
        <em>Soft Matter</em>,
      
      
        Vol. 16,
      
      
        No. 38,
      
      
        pp. 8854–8860,
      
      
        aug
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1039/d0sm01153c" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Leidenfrost droplets can be considered as soft engines capable of directly transforming heat into mechanical energy. Despite remarkable advancements in understanding the propulsion of Leidenfrost droplets on asymmetric structures, the complex dynamics of droplets in enclosed structures is not fully understood. To address this fundamental gap, we investigated the dynamics of Leidenfrost droplets restricted by metal disks. The disk alters the accumulation and release of the vapour generated by the droplet, and substantially changes its dynamic characteristics. Our experiments reveal the formation of oscillating multi-lobed structures when restricting the droplet within a disk. In comparison, patterning offset radial grooves on the surface of the disk rectifies the vapour flow and facilitates the self-propulsion of the droplet along the edge of the disk. Our work offers opportunities for developing soft and short-living actuators, which can operate at high temperatures.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Zhang2020" class="col-sm-10">
    
      <div class="title">All-Pass Parametric Image Registration</div>
      <div class="author">X. Zhang, 
                  <em>C. Gilliam</em>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Image Processing</em>,
      
      
        Vol. 29,
      
      
      
        pp. 5625–5640,
      
      
        apr
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/tip.2020.2984897" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/TIP2020.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="/assets/pdf/TIP2020_supplementary.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Image registration is a required step in many practical applications that involve the acquisition of multiple related images. In this paper, we propose a methodology to deal with both the geometric and intensity transformations in the image registration problem. The main idea is to modify an accurate and fast elastic registration algorithm (Local All-Pass - LAP) so that it returns a parametric displacement field, and to estimate the intensity changes by fitting another parametric expression. Although we demonstrate the methodology using a low-order parametric model, our approach is highly flexible and easily allows substantially richer parametrisations, while requiring only limited extra computation cost. In addition, we propose two novel quantitative criteria to evaluate the accuracy of the alignment of two images (’salience correlation’) and the number of degrees of freedom (’parsimony’) of a displacement field, respectively. Experimental results on both synthetic and real images demonstrate the high accuracy and computational efficiency of our methodology. Furthermore,  we demonstrate that the resulting displacement fields are more parsimonious than the ones obtained in other state-of-the-art image registration approaches.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">Book Chapters</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Ristic2020b" class="col-sm-10">
    
      <div class="title">Decentralised Scalable Search for a Hazardous Source in Turbulent Conditions</div>
      <div class="author">B. Ristic, and <em>C. Gilliam</em>
                
      </div>

      <div class="periodical">
      
          <em>In "Unmanned Robotic Systems and Applications" </em> (eds. Reyhanoglu, M. and De Cubber, G.),  IntechOpen,
      
      
      
      
      
        apr
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.5772/intechopen.86540" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The problem is autonomous coordinated search by an interconnected group of moving robots for the purpose of finding and localising a source of hazardous emissions (e.g., gas and particles). Dispersion of the emitted substance is assumed to be affected by turbulence, resulting in the absence of concentration gradients. The chapter proposes a search strategy that operates in a completely decentralised manner, as long as the communication network of the moving robots forms a connected graph. By decentralised operation, we mean that each moving robot is reasoning (i.e., estimating the source location and making decisions on robot motion) locally. Coordination of the group is achieved by consensus via communication with the neighbours only, in a manner which does not require global knowledge of the communication network topology.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Jelfs2020" class="col-sm-10">
    
      <div class="title">Application of Image Processing and Circular Statistics to 3D Cellular Alignment</div>
      <div class="author">
<a href="https://beteje.github.io/" target="_blank" rel="noopener noreferrer">B. Jelfs</a>, and <em>C. Gilliam</em>
                
      </div>

      <div class="periodical">
      
        <em>In Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA 2020)</em>, ,
      
      
      
      
        pp. 992–1000,
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9306340" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/APSIPA2020a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/beteje/Orientation" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
      <a href="https://drive.google.com/file/d/10lfZxjHlmyIchSNhOllNByRRIzx77MT9/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
    
    
    
      
      <a href="https://drive.google.com/file/d/1XcuMWBXWa53QZTYMBZzjku7emCAlEvGt/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Alignment and orientation of cells play an important part in the function of biological tissue. Recent developments in bioengineering using 3D scaffolds have created an increased need for computational techniques to measure orientation which extend beyond 2D measures to produce 3D measures of orientation. Initial studies of 3D alignment have focused on determining individual orientations, however, to truly understand the impact these structures have on the cellular alignment we need to understand the overall distribution of the orientations and their statistics. Hence, in this paper we develop an approach for determining 3D cellular alignment based on image gradients and directional statistics. The intensity gradients of the volumetric image are used to construct a 3D vector field and the local dominant orientations of this vector field then determined.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Kustner2020" class="col-sm-10">
    
      <div class="title">Deep-learning based motion-corrected image reconstruction in 4D magnetic resonance imaging of the body trunk</div>
      <div class="author">
<a href="http://www.midaslab.org/" target="_blank" rel="noopener noreferrer">T. Küstner</a>, J. Pan, 
                  <em>C. Gilliam</em>, H. Qi, G. Cruz, K. Hammernik, B. Yang, <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>, D. Rueckert, R. Botnar, C. Prieto, and S. Gatidis
      </div>

      <div class="periodical">
      
        <em>In Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA 2020)</em>, ,
      
      
      
      
        pp. 976–985,
      
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9306428" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/APSIPA2020b.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Respiratory and cardiac motion can cause artifacts in magnetic resonance imaging of the body trunk if patients cannot hold their breath or triggered acquisitions are not practical. Retrospective correction strategies usually cope with motion by fast imaging sequences with integrated motion tracking under free-movement conditions. These acquisitions perform sub-Nyquist sampling and retrospectively bin the data into the respective motion states, yielding subsampled and motion-resolved k-space data. The motion-resolved k-spaces are linked to each other by non-rigid deformation fields. The accurate estimation of such motion is thus an important task in the successful correction of respiratory and cardiac motion. Usually this problem is formulated in image space via diffusion, parametric-spline or optical flow methods. Image-based registration can be however impaired by aliasing artifacts or by estimation from low-resolution images. Subsequently, any motion-corrected reconstruction can be biased by errors in the deformation fields. In this work, we propose a novel deep-learning based motion-corrected 4D (3D spatial + time) image reconstruction which combines a non-rigid registration network and a(3+1)D reconstruction network. Non-rigid motion is estimated directly in k-space based on an optical flow idea and incorporated into the reconstruction network. The proposed method is evaluated on in-vivo 4D motion-resolved magnetic resonance images of patients with suspected liver or lung metastases and healthy subjects.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
      <span class="award badge"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">Best Paper Award<img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"></span>
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Mohammed2019" class="col-sm-10">
    
      <div class="title">Studying the Response of Aortic Endothelial Cells under Pulsatile Flow Using a Compact Microfluidic System</div>
      <div class="author">M. Mohammed, P. Thurgood, 
                  <em>C. Gilliam</em>, N. Nguyen, E. Pirogova, K. Peter, K. Khoshmanesh, and S. Baratchi
      </div>

      <div class="periodical">
      
        <em>Analytical Chemistry</em>,
      
      
        Vol. 91,
      
      
        No. 18,
      
      
        pp. 12077–12084,
      
      
        aug
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1021/acs.analchem.9b03247" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We describe a piezoelectric pumping system for studying the mechanobiology of human aortic endothelial cells (HAECs) under pulsatile flow in microfluidic structures. The system takes advantage of commercially available components, including pumps, flow sensors, and microfluidic channels, which can be easily integrated, programmed, and operated by cellular biologists. Proof-of-concept experiments were performed to elucidate the complex mechanotransduction processes of endothelial cells to pulsatile flow. In particular, we investigated the effect of atheroprone and atheroprotective pulsatile shear stress on endothelial cytoskeleton remodeling and distribution of beta-catenin, as well as nuclear shape and size. The system is simple to operate, relatively inexpensive, portable, and controllable, providing opportunities for studying the mechanobiology of endothelial cells using microfluidic technologies.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Thurgood2019" class="col-sm-10">
    
      <div class="title">Self-sufficient, low-cost microfluidic pumps utilising reinforced balloons</div>
      <div class="author">P. Thurgood, S. Aguilera Suarez, S. Chen, 
                  <em>C. Gilliam</em>, E. Pirogova, A. R. Jex, S. Baratchi, and K. Khoshmanesh
      </div>

      <div class="periodical">
      
        <em>Lab on a Chip</em>,
      
      
        Vol. 19,
      
      
        No. 17,
      
      
        pp. 2885–2896,
      
      
        jul
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1039/c9lc00618d" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Here, we introduce a simple method for increasing the inflation pressure of self-sufficient pressure pumps made of latex balloons. Our method involves reinforcing the latex balloon with elastane fibres to restrict the expansion of the balloon and increase its inflation pressure. This allowed us to increase the operational inflation pressure of a latex balloon from 2.5 to 25 kPa. Proof-of-concept experiments show the suitability of the reinforced balloon for inducing lateral forces and recirculating flows, which are employed for hydrodynamic capturing of large human monocytes. We also demonstrate the ability for the rapid exchange of solutions in repeated cycles upon manual squeezing of the reinforced balloons. We also show the suitability of the reinforced balloon for studying the mechanobiology of human aortic endothelial cells under various shear stress levels. The simplicity, portability, affordability, hyper-elasticity and scalability of the reinforced balloon pumps make them suitable for a wide range of microfluidic applications.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="TovarLopez2019" class="col-sm-10">
    
      <div class="title">A Microfluidic System for Studying the Effects of Disturbed Flow on Endothelial Cells</div>
      <div class="author">F. Tovar-Lopez, P. Thurgood, 
                  <em>C. Gilliam</em>, N. Nguyen, E. Pirogova, K. Khoshmanesh, and S. Baratchi
      </div>

      <div class="periodical">
      
        <em>Frontiers in Bioengineering and Biotechnology</em>,
      
      
        Vol. 7,
      
      
      
      
        apr
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.3389/fbioe.2019.00081" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
      <a href="https://github.com/ChrisGilliam/Stress_Fibre_Orientation" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Arterial endothelium experience physical stress associated with blood flow and play a central role in maintaining vascular integrity and homeostasis in response to hemodynamic forces. Blood flow within vessels is generally laminar and streamlined. However, abrupt changes in the vessel geometry due to branching, sharp turns or stenosis can disturb the laminar blood flow, causing secondary flows in the form of vortices. Such disturbed flow patterns activate pro-inflammatory phenotypes in endothelial cells, damaging the endothelial layer and can lead to atherosclerosis and thrombosis. Here, we report a microfluidic system with integrated ridge-shaped obstacles for generating controllable disturbed flow patterns. This system is used to study the effect of disturbed flow on the cytoskeleton remodeling and nuclear shape and size of cultured human aortic endothelial cells. Our results demonstrate that the generated disturbed flow changes the orientation angle of actin stress fibers and reduces the nuclear size while increases the nuclear circularity.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2019" class="col-sm-10">
    
      <div class="title">Possibilistic vs Evidential Valuation Algebra Networks</div>
      <div class="author">
                  <em>C. Gilliam</em>, B. Ristic, and M. Byrne
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Systems, Man and Cybernetics (SMC)</em>, Bari, Italy,
      
      
      
      
        pp. 2971–2977,
      
      
        oct
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/SMC.2019.8914305" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/SMC2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/SMC2019_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Realistic reasoning applications typically involve many interrelated variables and require the interpretation of data that is both heterogeneous in nature and affected by various types of uncertainty. Accordingly, in this paper we investigate the performance of valuation based algebra networks for reasoning in uncertain multivariate systems. Specifically, we consider networks built from two different approaches to modelling uncertainty: possibility theory and Dempster-Shafer evidence theory. To compare these differing networks, we propose a new possibilistic counterpart to the uncertain implication rule that exists in evidential networks. Using the Captain’s decision problem, we analyse the performance of these networks when estimating the number of days a ship will be delayed based on a mixture of uncertain knowledge. We demonstrate that the evidential network is more cautious to changes in uncertainty whereas the possibilistic network is more sensitive. This characteristic could allow the possibilistic network to be used to perform sensitivity analysis on a system.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Jayashankar2019" class="col-sm-10">
    
      <div class="title">LAP-Based Video Frame Interpolation</div>
      <div class="author">T. Jayashankar, P. Moulin, <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>, and <em>C. Gilliam</em>
                
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Image Processing (ICIP 2019)</em>, Taipei, Taiwan,
      
      
      
      
        pp. 4195–4199,
      
      
        sep
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICIP.2019.8803484" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICIP2019a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>High-quality video frame interpolation often necessitates accurate motion estimation, which can be obtained using modern optical flow methods. In this paper, we use the recently proposed Local All-Pass (LAP) algorithm to compute the optical flow between two consecutive frames. The resulting flow field is used to perform interpolation using cubic splines. We compare the interpolation results against a well-known optical flow estimation algorithm as well as against a recent con-volutional neural network scheme for video frame interpolation. Qualitative and quantitative results show that the LAP algorithm performs fast, high-quality video frame interpolation, and perceptually outperforms the neural network and the Lucas-Kanade method on a variety of test sequences.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Jelfs2019" class="col-sm-10">
    
      <div class="title">Fast Efficient Delay Estimation Using Local All-Pass Kalman Filters</div>
      <div class="author">
<a href="https://beteje.github.io/" target="_blank" rel="noopener noreferrer">B. Jelfs</a>, and <em>C. Gilliam</em>
                
      </div>

      <div class="periodical">
      
        <em>In Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA 2019)</em>, Lanzhou, China,
      
      
      
      
        pp. 1533–1539,
      
      
        nov
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/APSIPAASC47483.2019.9023238" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/APSIPA2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/APSIPA2019_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Delay estimation is a common problem in signal processing which becomes particularly challenging when the delay is time-varying and the recorded signals are non-stationary. While methods for time-varying delay (TVD) estimation exist many of these are based on maximum likelihood estimation and thus are not well suited to real-time implementation. In this paper we present a method for TVD estimation which is suitable for real-time non-stationary applications. The proposed method combines local all-pass (LAP) filters with a Kalman filter. By using measurement fusion to combine the outputs of several LAP filters in the Kalman filter we can accurately track TVDs whilst allowing for fast and efficient parallel computation. Illustrative simulations demonstrate the effectiveness of the proposed approach.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Wang2019a" class="col-sm-10">
    
      <div class="title">RRT* Trajectory Scheduling Using Angles-Only Measurements for AUV Recovery</div>
      <div class="author">X. Wang, S. Williams, D. Angley, 
                  <em>C. Gilliam</em>, T. Jackson, R. Ellem, A. Bessell, and B. Moran
      </div>

      <div class="periodical">
      
        <em>In Proc. International Conference on Information Fusion (FUSION 2019)</em>, Ottawa, Canada,
      
      
      
      
        pp. 1–6,
      
      
        jul
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
    
      
      <a href="/assets/pdf/FUSION2019a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Sensor trajectory optimisation involves extensive search over the sensor motion space against an optimisation criterion. The search under dynamic programming or fixed grid is often computationally nontrivial even for a myopic search scenario. In this paper, we study the problem of an autonomous underwater vehicle planning its return route to a moving recovery vessel. To complicate the issue, the AUV needs to localize the vessel using angle-only measurements. Accordingly, we propose a random sampling based trajectory planning algorithm that incorporates both a dynamic goal and the need to localize that goal. More precisely, we incorporate an information theoretic cost into a rapid-exploring random tree trajectory planning framework thus allowing the AUV to both localize and reach the recovery vessel. Our experimental results show that the proposed method may achieve the same trajectory optimisation performance as that under dynamic programming method but with greater computational efficiency.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Williams2019" class="col-sm-10">
    
      <div class="title">Dynamic Target Driven Trajectory Planning using RRT*</div>
      <div class="author">S. Williams, X. Wang, D. Angley, 
                  <em>C. Gilliam</em>, B. Moran, R. Ellem, T. Jackson, and A. Bessell
      </div>

      <div class="periodical">
      
        <em>In Proc. International Conference on Information Fusion (FUSION 2019)</em>, Ottawa, Canada,
      
      
      
      
        pp. 1–8,
      
      
        jul
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
    
    
    
      
      <a href="/assets/pdf/FUSION2019b.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we focus on dynamic trajectory planning for an autonomous underwater vehicle (AUV). Specifically, we are interested in planning the trajectory of an AUV as it returns to a moving recovery vessel. To aid in this task, the AUV is equipped with a passive, angle-only, sensor to enable localization of the recovery vessel. Accordingly, we present an algorithm that is capable of dynamically updating the trajectory of the AUV given measurement data from the passive sensor. Our approach is based on adapting a static trajectory planning algorithm from robotics, known as Rapidly-exploring Random Tree (RRT*), to allow for localization and tracking of a dynamic target (i.e. the recovery vessel). In contrast to dynamic programming or fixed grid trajectory planning, the RRT* offers a computationally efficient method for long-term trajectory planning with probabilistic guarantees of optimality. In this framework, we explore two options: trajectory planning based on minimising the distance to the target; and trajectory planning based on maximising the tracking accuracy of the target using an information theoretic cost. Using AUV recovery as an evaluation scenario, we analyse and evaluate the proposed trajectory planning algorithm against traditional dynamic programming methods. In particular, we consider trajectory planning in noisy and obstructed environments.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Zhang2019c" class="col-sm-10">
    
      <div class="title">Parametric Registration for Mobile Phone Images</div>
      <div class="author">X. Zhang, 
                  <em>C. Gilliam</em>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Image Processing (ICIP 2019)</em>, Taipei, Taiwan,
      
      
      
      
        pp. 1312–1316,
      
      
        sep
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICIP.2019.8803769" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICIP2019b.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Image registration is a significant step in a wide range of practical applications and it is a fundamental problem in various computer vision tasks. In this paper, we propose a highly accurate and fast parametric registration method for mobile phone photos. The proposed algorithm is based on a fast and accurate elastic registration algorithm, the Local All-Pass (LAP) algorithm, which performs in a coarse-to-fine manner. At each iteration, the LAP displacement field is fitted by a parametric model. Thus the image registration problem is equivalent to finding a few parameters to describe the displacement field. The fitting step can be performed very efficiently by solving a linear system of equations. In terms of the fitting model, it is easy to change the type of models to do the parametric fitting for specific applications. Experimental results on both synthetic and real images demonstrate the high accuracy and computational efficiency of the proposed algorithm.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2018" class="col-sm-10">
    
      <div class="title">Local All-Pass Geometric Deformations</div>
      <div class="author">
                  <em>C. Gilliam</em>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Image Processing</em>,
      
      
        Vol. 27,
      
      
        No. 2,
      
      
        pp. 1010–1025,
      
      
        feb
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/TIP.2017.2765822" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/TIP2017.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="/assets/pdf/TIP2017_supplementary.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper deals with the estimation of a deformation that describes the geometric transformation between two images. To solve this problem, we propose a novel framework that relies upon the brightness consistency hypothesis-a pixel’s intensity is maintained throughout the transformation. Instead of assuming small distortion and linearizing the problem (e.g. via Taylor Series expansion), we propose to interpret the brightness hypothesis as an all-pass filtering relation between the two images. The key advantages of this new interpretation are that no restrictions are placed on the amplitude of the deformation or on the spatial variations of the images. Moreover, by converting the all-pass filtering to a linear forward-backward filtering relation, our solution to the estimation problem equates to solving a linear system of equations, which leads to a highly efficient implementation. Using this framework, we develop a fast algorithm that relates one image to another, on a local level, using an all-pass filter and then extracts the deformation from the filter-hence the name ’Local All-Pass’ (LAP) algorithm. The effectiveness of this algorithm is demonstrated on a variety of synthetic and real deformations that are found in applications, such as image registration and motion estimation. In particular, when compared with a selection of image registration algorithms, the LAP obtains very accurate results for significantly reduced computation time and is very robust to noise corruption.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2018a" class="col-sm-10">
    
      <div class="title">Scheduling of Multistatic Sonobuoy Fields Using Multi-Objective Optimization</div>
      <div class="author">
                  <em>C. Gilliam</em>, B. Ristic, D. Angley, S. Suvorova, B. Moran, F. Fletcher, H. Gaetjens, and S. Simakov
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)</em>, Calgary, Canada,
      
      
      
      
        pp. 3206–3210,
      
      
        apr
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICASSP.2018.8462152" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2018b.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2018b_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Sonobuoy fields, comprising a network of transmitters and receivers, are commonly deployed to find and track underwater targets. For a given environment and sonobuoy field layout, the performance of such a field depends on the scheduling, that is, deciding which source should transmit, and which from a library of available waveforms should be transmitted at any given time. In this paper, we propose a novel scheduling framework based on multi-objective optimization. Specifically, we pose the two tasks of the sonobuoy field-tracking and searching-as separate, competing, objective functions. Using this framework, we propose a characterization of scheduling based on Pareto optimality. This characterization describes the trade-off between the search-track objectives and is demonstrated on realistic multistatic sonobuoy simulations.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2018b" class="col-sm-10">
    
      <div class="title">Time-Varying Delay Estimation Using Common Local All-Pass Filters with Application to Surface Electromyography</div>
      <div class="author">
                  <em>C. Gilliam</em>, A. Bingham, <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>, and <a href="https://beteje.github.io/" target="_blank" rel="noopener noreferrer">B. Jelfs</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)</em>, Calgary, Canada,
      
      
      
      
        pp. 841–845,
      
      
        apr
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICASSP.2018.8461390" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2018a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2018a_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Estimation of conduction velocity (CV) is an important task in the analysis of surface electromyography (sEMG). The problem can be framed as estimation of a time-varying delay (TVD) between electrode recordings. In this paper we present an algorithm which incorporates information from multiple electrodes into a single TVD estimation. The algorithm uses a common all-pass filter to relate two groups of signals at a local level. We also address a current limitation of CV estimators by providing an automated way of identifying the innervation zone from a set of electrode recordings, thus allowing incorporation of the entire array into the estimation. We validate the algorithm on both synthetic and real sEMG data with results showing the proposed algorithm is both robust and accurate.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2018c" class="col-sm-10">
    
      <div class="title">Covariance Cost Functions for Scheduling Multistatic Sonobuoy Fields</div>
      <div class="author">
                  <em>C. Gilliam</em>, D. Angley, S. Williams, B. Ristic, B. Moran, F. Fletcher, and S. Simakov
      </div>

      <div class="periodical">
      
        <em>In Proc. International Conference on Information Fusion (FUSION 2018)</em>, Cambridge, UK,
      
      
      
      
        pp. 1–8,
      
      
        jul
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.23919/ICIF.2018.8455466" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/FUSION2018.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/FUSION2018_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Sonobuoy fields, comprising a network of sonar transmitters and receivers, are used to find and track underwater targets. For a given environment and sonobuoy field layout, the performance of such a field depends on the scheduling, that is, deciding which source should transmit, and which waveform should be transmitted at any given time. In this paper, we explore the choice of cost function used in myopic scheduling and its effect on tracking performance. Specifically, we consider 5 different cost functions derived from the predicted error covariance matrix of the track. Importantly, our cost functions combine both positional and velocity covariance information to allow the scheduler to choose the optimum source-waveform action. Using realistic multistatic sonobuoy simulations, we demonstrate that each cost function results in a different choice of source-waveform actions, which in turn affects the performance of the scheduler. In particular, we show there is a trade-off between position and velocity error performance such that no one cost function is superior in both.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2018d" class="col-sm-10">
    
      <div class="title">Estimating Muscle Fibre Conduction Velocity in the Presence of Array Misalignment</div>
      <div class="author">
                  <em>Christopher Gilliam</em>, and <a href="https://beteje.github.io/" target="_blank" rel="noopener noreferrer">Beth Jelfs</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA 2018)</em>, Honolulu, Hawaii, USA,
      
      
      
      
      
        nov
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.23919/apsipa.2018.8659741" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/APSIPA2018.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/APSIPA2018_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Surface electromyography (sEMG) has the potential to provide valuable information regarding the status and health of a muscle. In particular, recent developments in high density sEMG (HD-sEMG), which allow simultaneous recordings from a greater number of electrodes, enable the calculation of muscle attributes such as the conduction velocity of motor unit action potentials. However, as with  standard recording montages, HD-sEMG requires careful placement of the electrodes to align with the direction of the muscle fibres, thus limiting practical applications. In this paper we demonstrate an algorithm for calculating muscle fibre conduction velocity which is independent of the alignment of the array. The algorithm automatically corrects for the misalignment of the array whilst estimating the conduction velocity using common local all-pass (CLAP) filters. Specifically, the misalignment is modelled as a rotation of the array relative to the fibre and this rotation is estimated by iteratively fitting the model to the output of the CLAP filters. We validate the proposed algorithm on simulated HD-sEMG data generated from a realistic biological model, demonstrating that the algorithm obtains an accurate estimate of the conduction velocity even when the array is misaligned.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
</ol>

  <h2 class="year">2017</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Kustner2017" class="col-sm-10">
    
      <div class="title">MR-based respiratory and cardiac motion correction for PET imaging</div>
      <div class="author">
<a href="http://www.midaslab.org/" target="_blank" rel="noopener noreferrer">T. Küstner</a>, M. Schwartz, P. Martirosian, S. Gatidis, F. Seith, 
                  <em>C. Gilliam</em>, <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>, H. Fayad, D. Visvikis, F. Schick, B. Yang, H. Schmidt, and N.F. Schwenzer
      </div>

      <div class="periodical">
      
        <em>Medical Image Analysis</em>,
      
      
        Vol. 42,
      
      
      
        pp. 129–144,
      
      
        dec
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1016/j.media.2017.08.002" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/Kustner2017.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Purpose: To develop a motion correction for Positron-Emission-Tomography (PET) using simultaneously acquired magnetic-resonance (MR) images within 90.

Methods: A 90s MR acquisition allows the generation of a cardiac and respiratory motion model of the body trunk. Thereafter, further diagnostic MR sequences can be recorded during the PET examination without any limitation. To provide full PET scan time coverage, a sensor fusion approach maps external motion signals (respiratory belt, ECG-derived respiration signal) to a complete surrogate signal on which the retrospective data binning is performed. A joint Compressed Sensing reconstruction and motion estimation of the subsampled data provides motion-resolved MR images (respiratory + cardiac). A 1-POINT DIXON method is applied to these MR images to derive a motion-resolved attenuation map. The motion model and the attenuation map are fed to the Customizable and Advanced Software for Tomographic Reconstruction (CASToR) PET reconstruction system in which the motion correction is incorporated. All reconstruction steps are performed online on the scanner via Gadgetron to provide a clinically feasible setup for improved general applicability. The method was evaluated on 36 patients with suspected liver or lung metastasis in terms of lesion quantification (SUVmax, SNR, contrast), delineation (FWHM, slope steepness) and diagnostic confidence level (3-point Likert-scale).

Results: A motion correction could be conducted for all patients, however, only in 30 patients moving lesions could be observed. For the examined 134 malignant lesions, an average improvement in lesion quantification of 22%, delineation of 64% and diagnostic confidence level of 23% was achieved.

Conclusion: The proposed method provides a clinically feasible setup for respiratory and cardiac motion correction of PET data by simultaneous short-term MRI. The acquisition sequence and all reconstruction steps are publicly available to foster multi-center studies and various motion correction scenarios.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Zhang2017" class="col-sm-10">
    
      <div class="title">Iterative fitting after elastic registration: An efficient strategy for accurate estimation of parametric deformations</div>
      <div class="author">X. Zhang, 
                  <em>C. Gilliam</em>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Image Processing (ICIP 2017)</em>, Beijing, China,
      
      
      
      
        pp. 1492–1496,
      
      
        sep
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICIP.2017.8296530" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICIP2017.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose an efficient method for image registration based on iteratively fitting a parametric model to the output of an elastic registration. It combines the flexibility of elastic registration - able to estimate complex deformations - with the robustness of parametric registration - able to estimate very large displacement. Our approach is made feasible by using the recent Local All-Pass (LAP) algorithm; a fast and accurate filter-based method for estimating the local deformation between two images. Moreover, at each iteration we fit a linear parametric model to the local deformation which is equivalent to solving a linear system of equations (very fast and efficient). We use a quadratic polynomial model however the framework can easily be extended to more complicated models. The significant advantage of the proposed method is its robustness to model mis-match (e.g. noise and blurring). Experimental results on synthetic images and real images demonstrate that the proposed algorithm is highly accurate and outperforms a selection of image registration approaches.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2016" class="col-sm-10">
    
      <div class="title">Finding the Minimum Rate of Innovation in the Presence of Noise</div>
      <div class="author">
                  <em>C. Gilliam</em>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2016)</em>, Shanghai, China,
      
      
      
      
      
        mar
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/icassp.2016.7472432" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2016.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2016_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently, sampling theory has been broadened to include a class of non-bandlimited signals that possess finite rate of innovation (FRI). In this paper, we consider the problem of determining the minimum rate of innovation (RI) in a noisy setting. First, we adapt a recent model-fitting algorithm for FRI recovery and demonstrate that it achieves the Cramér-Rao bounds. Using this algorithm, we then present a framework to estimate the minimum RI based on fitting the sparsest model to the noisy samples whilst satisfying a mean squared error (MSE) criterion - a signal is recovered if the output MSE is less than the input MSE. Specifically, given a RI, we use the MSE criterion to judge whether our model-fitting has been a success or a failure. Using this output, we present a Dichotomic algorithm that performs a binary search for the minimum RI and demonstrate that it obtains a sparser RI estimate than an existing information criterion approach.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2016a" class="col-sm-10">
    
      <div class="title">3D Motion Flow Estimation using Local All-Pass Filters</div>
      <div class="author">
                  <em>C. Gilliam</em>, <a href="http://www.midaslab.org/" target="_blank" rel="noopener noreferrer">T. Küstner</a>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Symposium on Biomedical Imaging (ISBI 2016)</em>, Prague, Czech Republic,
      
      
      
      
        pp. 282–285,
      
      
        apr
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/isbi.2016.7493264" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ISBI2016.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/ISBI2016_Poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="/assets/pdf/ISBI2016_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Fast and accurate motion estimation is an important tool in biomedical imaging applications such as motion compensation and image registration. In this paper, we present a novel algorithm to estimate motion in volumetric images based on the recently developed Local All-Pass (LAP) optical flow framework. The framework is built upon the idea that any motion can be regarded as a local rigid displacement and is hence equivalent to all-pass filtering. Accordingly, our algorithm aims to relate two images, on a local level, using a 3D all-pass filter and then extract the local motion flow from the filter. As this process is based on filtering, it can be efficiently repeated over the whole image volume allowing fast estimation of a dense 3D motion. We demonstrate the effectiveness of this algorithm on both synthetic motion flows and in-vivo MRI data involving respiratory motion. In particular, the algorithm obtains greater accuracy for significantly reduced computation time when compared to competing approaches.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
</ol>

  <h2 class="year">2015</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Dogan2015" class="col-sm-10">
    
      <div class="title">Reconstruction of Finite Rate of Innovation Signals with Model-Fitting Approach</div>
      <div class="author">Z. Doğan, 
                  <em>C. Gilliam</em>, <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>, and D. Van De Ville
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Signal Processing</em>,
      
      
        Vol. 63,
      
      
        No. 22,
      
      
        pp. 6024–6036,
      
      
        nov
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/TSP.2015.2461513" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/Dogan2015.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Finite rate of innovation (FRI) is a recent framework for sampling
	and reconstruction of a large class of parametric signals that are
	characterized by finite number of innovations (parameters) per unit
	interval. In the absence of noise, exact recovery of FRI signals
	has been demonstrated. In the noisy scenario, there exist techniques
	to deal with non-ideal measurements. Yet, the accuracy and resiliency
	to noise and model mismatch are still challenging problems for real-world
	applications. We address the reconstruction of FRI signals, specifically
	a stream of Diracs, from few signal samples degraded by noise and
	we propose a new FRI reconstruction method that is based on a model-fitting
	approach related to the structured-TLS problem. The model-fitting
	method is based on minimizing the training error, that is, the error
	between the computed and the recovered moments (i.e., the FRI-samples
	of the signal), subject to an annihilation system. We present our
	framework for three different constraints of the annihilation system.
	Moreover, we propose a model order selection framework to determine
	the innovation rate of the signal; i.e., the number of Diracs by
	estimating the noise level through the training error curve. We compare
	the performance of the model-fitting approach with known FRI reconstruction
	algorithms and Cramer-Rao’s lower bound (CRLB) to validate these
	contributions.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Blu2015" class="col-sm-10">
    
      <div class="title">Approximation Order of the LAP Optical Flow Algorithm</div>
      <div class="author">
<a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>, P. Moulin, and <em>C. Gilliam</em>
                
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Image Processing (ICIP 2015)</em>, Québec City, Canada,
      
      
      
      
        pp. 48 - 52,
      
      
        sep
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICIP.2015.7350757" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICIP2015a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICIP2015a_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Estimating the displacements between two images is often addressed
	using a small displacement assumption, which leads to what is known
	as the optical flow equation. We study the quality of the underlying
	approximation for the recently developed Local All-Pass (LAP) optical
	flow algorithm, which is based on another approach–displacements
	result from filtering. While the simplest version of LAP computes
	only first-order differences, we show that the order of LAP approximation
	is quadratic, unlike standard optical flow equation based algorithms
	for which this approximation is only linear. More generally, the
	order of approximation of the LAP algorithm is twice larger than
	the differentiation order involved. The key step in the derivation
	is the use of Padé approximants.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2015" class="col-sm-10">
    
      <div class="title">Local All-Pass Filters for Optical Flow Estimation</div>
      <div class="author">
                  <em>C. Gilliam</em>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2015)</em>, Brisbane, Australia,
      
      
      
      
        pp. 1533–1537,
      
      
        apr
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICASSP.2015.7178227" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2015.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2015_Poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="/assets/pdf/ICASSP2015_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The optical flow is a velocity field that describes the motion of
	pixels within a sequence (or set) of images. Its estimation plays
	an important role in areas such as motion compensation, object tracking
	and image registration. In this paper, we present a novel framework
	to estimate the optical flow using local all-pass filters. Instead
	of using the optical flow equation, the framework is based on relating
	one image to another, on a local level, using an all-pass filter
	and then extracting the optical flow from the filter. Using this
	framework, we present a fast novel algorithm for estimating a smoothly
	varying optical flow, which we term the Local All-Pass (LAP) algorithm.
	We demonstrate that this algorithm is consistent and accurate, and
	that it outperforms three state-of-the-art algorithms when estimating
	constant and smoothly varying flows. We also show initial competitive
	results for real images.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Li2015" class="col-sm-10">
    
      <div class="title">A Multi-Frame Optical Flow Spot Tracker</div>
      <div class="author">
<a href="http://lijz.io/" target="_blank" rel="noopener noreferrer">J. Li</a>, 
                  <em>C. Gilliam</em>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Image Processing (ICIP 2015)</em>, Québec City, Canada,
      
      
      
      
        pp. 3670–3674,
      
      
        sep
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICIP.2015.7351489" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICIP2015b.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICIP2015b_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Accurate and robust spot tracking is a necessary tool for quantitative
	motion analysis in fluorescence microscopy images. Few trackers however
	consider the underlying dynamics present in biological systems. For
	example, the collective motion of cells often exhibits both fast
	dynamics, i.e. Brownian motion, and slow dynamics, i.e. time-invariant
	stationary motion. In this paper, we propose a novel, multi-frame,
	tracker that exploits this stationary motion. More precisely, we
	first estimate the stationary motion and then use it to guide the
	spot tracker. We obtain the stationary motion by adapting a recent
	optical flow algorithm that relates one image to another locally
	using an all-pass filter. We perform this operation over all the
	image frames simultaneously and estimate a single, stationary optical
	flow. We compare the proposed tracker with two existing techniques
	and show that our approach is more robust to high noise and varying
	structure. In addition, we also show initial experiments on real
	microscopy images.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li>
</ol>

  <h2 class="year">2014</h2>
  <h2 class="bibliography">Journal Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2014" class="col-sm-10">
    
      <div class="title">On the Spectrum of the Plenoptic Function</div>
      <div class="author">
                  <em>C. Gilliam</em>, <a href="https://www.commsp.ee.ic.ac.uk/~pld/" target="_blank" rel="noopener noreferrer">P. L. Dragotti</a>, and M. Brookes
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Image Processing</em>,
      
      
        Vol. 23,
      
      
        No. 2,
      
      
        pp. 502–516,
      
      
        feb
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/TIP.2013.2292363" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/TIP2014.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The plenoptic function is a powerful tool to analyze the properties
	of multi-view image data sets. In particular, the understanding of
	the spectral properties of the plenoptic function is essential in
	many computer vision applications, including image-based rendering.
	In this paper, we derive for the first time an exact closed-form
	expression of the plenoptic spectrum of a slanted plane with finite
	width and use this expression as the elementary building block to
	derive the plenoptic spectrum of more sophisticated scenes. This
	is achieved by approximating the geometry of the scene with a set
	of slanted planes and evaluating the closed-form expression for each
	plane in the set. We then use this closed-form expression to revisit
	uniform plenoptic sampling. In this context, we derive a new Nyquist
	rate for the plenoptic sampling of a slanted plane and a new reconstruction
	filter. Through numerical simulations, on both real and synthetic
	scenes, we show that the new filter outperforms alternative existing
	filters.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>
<h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2014a" class="col-sm-10">
    
      <div class="title">Fitting instead of annihilation: Improved recovery of noisy FRI signals</div>
      <div class="author">
                  <em>C. Gilliam</em>, and <a href="https://www.ee.cuhk.edu.hk/~tblu/monsite/phps/" target="_blank" rel="noopener noreferrer">T. Blu</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2014)</em>, Florence, Italy,
      
      
      
      
        pp. 51–55,
      
      
        may
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICASSP.2014.6853556" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2014.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2014_Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently, classical sampling theory has been broadened to include
	a class of non-bandlimited signals that possess finite rate of innovation
	(FRI). In this paper we consider the reconstruction of a periodic
	stream of Diracs from noisy samples. We demonstrate that its noiseless
	FRI samples can be represented as a ratio of two polynomials. Using
	this structure as a model, we propose recovering the FRI signal using
	a model fitting approach rather than an annihilation method. We present
	an algorithm that fits this model to the noisy samples and demonstrate
	that it has low computation cost and is more reliable than two state-of-the-art
	methods.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>

  <h2 class="year">2013</h2>
  <h2 class="bibliography">Book Chapters</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2013" class="col-sm-10">
    
      <div class="title">Image-Based Rendering and the Sampling of the Plenoptic Function</div>
      <div class="author">
                  <em>C. Gilliam</em>, M. Brookes, and <a href="https://www.commsp.ee.ic.ac.uk/~pld/" target="_blank" rel="noopener noreferrer">P. L. Dragotti</a>
                  
      </div>

      <div class="periodical">
      
          <em>In "Emerging Technologies for 3D Video" </em> (eds. Dufaux, F. and Pesquet-Popescu, B. and Cagnazzo, M.),  John Wiley &amp; Sons, Ltd,
      
      
      
      
        pp. 231–248,
      
      
        apr
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1002/9781118583593.ch12" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Image based rendering (IBR) is a technique for producing arbitrary
	views of a scene using multiple images instead of exact object models.
	The central concept is that each image comprises a collection of
	light rays and a new view is interpolated from these light rays.
	If we modelled the light rays using a 7D function, known as the plenoptic
	function, then IBR can be viewed in terms of sampling and reconstruction.
	Therefore the important goal of minimising the number of images required
	in IBR, whilst maintaining rendering quality, can be examined through
	sampling analysis of the plenoptic function. In this context, the
	chapter examines the state-of-the-art in plenoptic sampling theory.
	It focuses on both uniform and adaptive sampling of the plenoptic
	function. In particular, it presents theoretical results for uniform
	sampling based on spectral analysis of the plenoptic function and
	algorithms for adaptive plenoptic sampling.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>

  <h2 class="year">2012</h2>
  <h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2012" class="col-sm-10">
    
      <div class="title">Image based rendering with depth cameras: How many are needed?</div>
      <div class="author">
                  <em>C. Gilliam</em>, J. Pearson, M. Brookes, and <a href="https://www.commsp.ee.ic.ac.uk/~pld/" target="_blank" rel="noopener noreferrer">P. L. Dragotti</a>
                  
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012)</em>, Kyoto, Japan,
      
      
      
      
        pp. 5437–5440,
      
      
        mar
      
      
        2012
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICASSP.2012.6289151" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICASSP2012.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Image based rendering is a technique for producing arbitrary viewpoints
	of a scene using multiple images instead of exact object models.
	The recent emergence of low-price, fast, and reliable cameras for
	measuring depth makes possible the augmentation of traditional color
	images with depth images. This combination promises to improve the
	rendering quality of an arbitrary viewpoint and thus have a great
	impact on IBR. A key issue is to understand, for any particular scene
	of interest, how many depth images and how many color images are
	necessary in order to obtain good rendering results. In this paper,
	using a framework akin to the plenoptic function, we perform a spectral
	analysis of multi-view depth images in order to determine the relationship
	between the number of depth and color images required. Our analysis
	is then validated using both synthetic and real images.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>

  <h2 class="year">2011</h2>
  <h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2011" class="col-sm-10">
    
      <div class="title">Adaptive Plenoptic Sampling</div>
      <div class="author">
                  <em>C. Gilliam</em>, <a href="https://www.commsp.ee.ic.ac.uk/~pld/" target="_blank" rel="noopener noreferrer">P. L. Dragotti</a>, and M. Brookes
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Image Processing (ICIP 2011)</em>, Brussels, Belgium,
      
      
      
      
        pp. 2581–2584,
      
      
        sep
      
      
        2011
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICIP.2011.6116192" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICIP2011.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The plenoptic function enables Image-based rendering (IBR) to be viewed
	in terms of sampling and reconstruction. Thus the spatial sampling
	rate can be determined through spectral analysis of the plenoptic
	function. In this paper we present a method of nonuniformly sampling
	a scene, with a smoothly varying surface, given a finite number of
	samples. This method approximates such a scene with a set of slanted
	planes subject to the constraint of finite number of samples. We
	use the recent spectral analysis of a single slanted plane to determine
	a piecewise constant spatial sampling rate for the scene. Finally,
	we show that this sampling rate results in a nonuniform sampling
	scheme that reconstructs the plenoptic function beyond that of uniform
	sampling.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>

  <h2 class="year">2010</h2>
  <h2 class="bibliography">Conference Articles</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div id="Gilliam2010" class="col-sm-10">
    
      <div class="title">A Closed-Form Expression for the Bandwidth of the Plenoptic Function under Finite Field of View Constraints</div>
      <div class="author">
                  <em>C. Gilliam</em>, <a href="https://www.commsp.ee.ic.ac.uk/~pld/" target="_blank" rel="noopener noreferrer">P. L. Dragotti</a>, and M. Brookes
      </div>

      <div class="periodical">
      
        <em>In Proc. IEEE International Conference on Image Processing (ICIP 2010)</em>, Hong Kong,
      
      
      
      
        pp. 3965–3968,
      
      
        sep
      
      
        2010
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
    
    
      <a href="http://dx.doi.org/10.1109/ICIP.2010.5650038" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">doi</a>
    
    
    
    
      
      <a href="/assets/pdf/ICIP2010.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICIP2010_Poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The plenoptic function enables Image-based rendering (IBR) to be viewed
	in terms of sampling and reconstruction. Thus the spatial sampling
	rate can be determined through spectral analysis of the plenoptic
	function. In this paper we examine the bandwidth of the plenoptic
	function when both the field of view and the scene width are finite.
	This analysis is carried out on two planar Lambertian scenes, a fronto-parallel
	plane and a slanted plane, and in both cases the texture is bandlimited.
	We derive an exact closed-form expression for the plenoptic spectrum
	of a slanted plane with sinusoidal texture. We show that in both
	cases the finite constraints lead to band-unlimited spectra. By determining
	the essential bandwidth, we derive a sampling curve that gives an
	adequate camera spacing for a given distance between the scene and
	the camera line.</p>
    </div>
    
  </div>

  <div class="col-sm-2 abbr">
  </div>
</div>
</li></ol>


</div>

    </article>

  </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Christopher  Gilliam. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
